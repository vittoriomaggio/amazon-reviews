\chapter{Analisi tramite modelli supervisionati}
		Per terminare la nostra analisi, abbiamo scelto di allenare determinati modelli sui dati in \textit{input} per fare delle previsioni sul \textit{sentiment} e confrontare i valori ottenuti con quelli effettivi del \textit{dataset}. Prima di entrare nei dettagli implementativi rimandiamo all'attenzione del lettore alcuni richiami teorici circa i modelli da noi utilizzati: \textit{Logistic Regression}, \textit{Support Vector Machine}, \textit{Neural Network}e le misure associate a ogni modello; queste ultime saranno visibili in Appendice \ref{cap:Misure}. Si noti che dei tre modelli, quello che risulta avere accuratezza migliore è la \textit{Logistic Regression}, seguita dalla \textit{Support Vector Machine} e  infine dalla \textit{Neural Network}. 
		
			
		\section{Logistic Regression}
			La regressione logistica è un algoritmo di classificazione di \textit{Machine Learning} che viene utilizzato per prevedere la probabilità di una variabile dipendente categoriale. Nella regressione logistica, la variabile dipendente è una variabile binaria che contiene dati codificati come \verb|1| (sì, esito positivo) O \verb|0| (no, esito negativo). La regressione logistica binaria richiede che: la variabile dipendente sia binaria; le variabili indipendenti siano indipendenti l'una dall'altra e linearmente correlate alle probabilità del registro; la regressione logistica richiede campioni di dimensioni piuttosto grandi.
			
			

		\section{Support Vector Machine}
			Nell'apprendimento automatico , le \textit{Support Vector Machine} \footnote{SVM:macchine di supporto vettoriale}, sono modelli di apprendimento supervisionato con algoritmi di apprendimento associati che analizzano i dati utilizzati per l'analisi di classificazione e regressione. Dato un insieme di esempi di addestramento, ognuno segnato come appartenente all'una o all'altra di due categorie, un algoritmo di addestramento SVM costruisce un modello che assegna nuovi esempi a una categoria o all'altra, rendendolo un classificatore lineare binario non probabilistico. Un modello SVM è una rappresentazione degli esempi come punti nello spazio, mappati in modo tale che gli esempi delle categorie separate siano divisi da uno spazio vuoto il più ampio possibile. Nuovi esempi vengono quindi mappati nello stesso spazio e previsti per appartenere a una categoria in base al lato dello spazio su cui cadono.
		
				
		\section{Reti neurali}
			Una rete neurale è un sistema computazionale che crea previsioni basate su dati esistenti. In altre parole esegue calcoli per rilevare le caratteristiche e decide se un input appartiene o meno ad una specifica classe.\\			
			Una rete neurale è composta da tre parti principali:
			\begin{description}
				\item[] \textbf{Livelli di input}: accettano input in base a dati esistenti. Nel nostro caso \verb|5000| neuroni per ogni \textit{feature}.
				\item[] \textbf{Livelli nascosti}: utilizzano la \textit{backpropagation} per ottimizzare i pesi delle variabili di input al fine di migliorare la potenza predittiva del modello. Il nostro progetto ha previsto \verb|3| livelli composti rispettivamente da \verb|700|, \verb|400| e \verb|100| neuroni.
				\item[] \textbf{Livelli di output}: \textit{output} di previsioni basate sui dati dell'input e dei livelli nascosti. Nel nostro caso \verb|5| neuroni, uno per ogni punteggio delle stelle di \textit{amazon} (da \verb|1| a \verb|5|)
			\end{description}
				
	
	
		\section{Calcolo della misure di performance}
			In questa breve sezione verrà fornito un ripasso teorico delle misure di \textit{performance}. I valori calcolati per ogni modello sono visibili nell'Appendice \ref{cap:Misure}.
			\begin{itemize}
				\item \textbf{Matrice di confusione}: restituisce una rappresentazione dell'accuratezza di una classificazione statistica. In particolare ogni colonna della matrice rappresenta i valori reali, mentre ogni riga rappresenta i valori predetti.
					
				\item \textbf{Precision}: capacità di un modello di classificazione di identificare solo i dati pertinenti). Essa è data dal rapporto tra veri positivi(TP) e la somma di veri positivi(TP) e falsi positivi(FP).	
					\begin{equation}
					\text{Precision} = \frac{\text{TP}}{\text{TP} + \text{FP}} \\
					\end{equation}
				
				\item \textbf{Accuratezza}: capacità di un modello di trovare tutti i casi veritieri, ovvero quante istanze vengano classificate correttamente. Questa è la somma dei veri positivi più i veri negativi diviso il totale dei dati.
					\begin{equation}
					\text{Accuratezza} = \frac{\text{TP} + \text{TN}}{\text{TP} + \text{TN} + \text{FP} + \text{FN}} \\
					\end{equation}
				
				\item \textbf{Recall/Sensitività/TPR}: capacità di un modello di trovare tutti i casi pertinenti all’interno di una serie di dati; quindi l'abilità nell'identificare i positivi. Matematicamente la sua definizione è data dal rapporto tra veri positivi (TP) e la somma di veri positivi (TP) e falsi negativi (FN).
					\begin{equation}
					\text{Recall} = \frac{\text{TP}}{\text{TP} + \text{FN}} \\
					\end{equation}
				
				\item \textbf{F1-measure}: media armonica di precisione e richiamo, prese entrambe le metriche. Un punteggio di F1 è considerato perfetto quando è pari a \verb|1|, mentre un fallimento se pari a \verb|0|. 		
			\end{itemize}
	
	


%		PRECISION
%		logistic precision: [0.66096423 0.33888889 0.91858019]
%		svm		 precision: [0.63319088 0.29874214 0.92041320]
%		nn		 precision: [0.6420373  0.25677603 0.92769048]
%								log 	    log		     nn
%								
%		RECALL
%		logistic recall: [0.485992   0.09090909 0.98210184]
%		svm		 recall: [0.50829045 0.07078987 0.98071401]
%		nn		 recall: [0.51172098 0.13412817 0.9719085 ]
%							nn 	    	nn		     log
%		ACCURATEZZA
%		logistic acc: 0.896068703881269
%		svm		 acc: 0.8953599866594405
%		nn		 acc: 0.8914828865635552
%							log			
%							
%		F1-MEASURE
%		logistic measure: [0.5601318  0.14336075 0.94927955]
%		svm		 measure: [0.56390739 0.11445783 0.94960728]
%		nn		 measure: [0.56951957 0.17621145 0.94928485]
%								nn			nn			nn
							
							
